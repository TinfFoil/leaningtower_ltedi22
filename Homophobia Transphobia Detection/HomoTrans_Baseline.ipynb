{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LT-EDI2022-Homo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dDPXdf1xA5tz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "dDPXdf1xA5tz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z1bi2_ig7_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ce8180-2523-44dd-f516-f334282f60a6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip install transformers\n",
        "!pip install bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRSrY2V1tCtQ",
        "outputId": "a67e6158-3a02-49a3-d3f0-aeb588091c13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') \n",
        "model_save_name = 'homo.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_GN_E0I8y16"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3iRQxkT7yBj"
      },
      "source": [
        "#Prepare data - HOMO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwIDmk9R8xXK"
      },
      "source": [
        "data = pd.read_excel(\"homo_train.xlsx\")\n",
        "data = data.dropna()\n",
        "data = data.rename(columns={\"category\": \"labels\"})\n",
        "data = data.rename(columns={'text            ': 'text'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we set non anti lgbt content to 0, others homophobic to 1 and transphobic to 2\n",
        "def label_col (row):\n",
        "  if row['labels'] == 'Non-anti-LGBT+ content':\n",
        "    return 0\n",
        "  elif row['labels'] == 'Homophobic':\n",
        "    return 1\n",
        "  elif row['labels'] == 'Transphobic':\n",
        "    return 2"
      ],
      "metadata": {
        "id": "BBvHR-XYf_p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['labels'] = data.apply(lambda row: label_col(row), axis=1)\n",
        "data.to_csv('data.csv')"
      ],
      "metadata": {
        "id": "FEKc_eU2jdAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New file starts from here"
      ],
      "metadata": {
        "id": "njVMBHGUlc0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "xMxtEd66lD-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDI4mPrll4xb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset in traning and validation(test)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "    data.index.values,\n",
        "    data.labels.values,\n",
        "    test_size=0.10,\n",
        "    random_state=17,\n",
        "    stratify=data.labels.values\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QQLtyK9mBNm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "d120d8b3-bc11-486b-9fb2-c166d5fdd5ce"
      },
      "source": [
        "# Check datasets composition\n",
        "data['data_type'] = ['not_set'] * data.shape[0]\n",
        "data.loc[X_train, 'data_type'] = 'train'\n",
        "data.loc[X_val, 'data_type'] = 'val'\n",
        "data.groupby(['labels', 'data_type']).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f9899881-4773-462c-87eb-01133f425e88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>train</th>\n",
              "      <td>2700</td>\n",
              "      <td>2699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>301</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>train</th>\n",
              "      <td>141</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <th>train</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9899881-4773-462c-87eb-01133f425e88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9899881-4773-462c-87eb-01133f425e88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9899881-4773-462c-87eb-01133f425e88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  Unnamed: 0  text\n",
              "labels data_type                  \n",
              "0      train            2700  2699\n",
              "       val               301   301\n",
              "1      train             141   141\n",
              "       val                16    16\n",
              "2      train               6     6"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQIN3ZlyCJou",
        "outputId": "f1c42490-19cb-42c4-8702-b744d2c112cc"
      },
      "source": [
        "# Encode training dataset using the tokenizer\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    data[data.data_type == 'train'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Encode validation dataset using the tokenizer\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    data[data.data_type == 'val'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,  \n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lokaxrUnzD3O",
        "outputId": "cba7f230-c453-4eac-be6b-bca051f3e1f9"
      },
      "source": [
        "# Extract IDs, attention masks and labels from training dataset\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(data[data.data_type == 'train'].labels.values)\n",
        "labels_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfNUxIKHzEoL"
      },
      "source": [
        "# Extract IDs, attention masks and labels from validation dataset\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(data[data.data_type == 'val'].labels.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu87dR50zLTe",
        "outputId": "57bc9db3-9a3e-40c8-d8d6-06f3e76e6e66"
      },
      "source": [
        "# Create train and validation dataset from extracted features\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
        "print(\"Train dataset length: {}\\nValidation dataset length: {}\".format(len(dataset_train), len(dataset_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset length: 2846\n",
            "Validation dataset length: 317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fFmToCCzTz3"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Define the size of each batch\n",
        "batch_size = 16\n",
        "\n",
        "# Load training dataset\n",
        "dataloader_train= DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# Load valuation dataset\n",
        "dataloader_val= DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uxMSx4QzYCj",
        "outputId": "1690187e-00e0-4563-c636-c09f96dd5398"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "# Load pre-trained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels = 3,\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtMGAzonzuS9"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Define model optimizer -> Adam\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5, \n",
        "    eps=1e-8\n",
        ")\n",
        "# Define model scheduler\n",
        "epochs = 4\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do2fGu4UzyuR"
      },
      "source": [
        "import random\n",
        "\n",
        "# Define random seeds\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN_n5FzKz1bE",
        "outputId": "4e3b111f-4712-424a-e41d-beb1482d65b5"
      },
      "source": [
        "# Define processor type for torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5jYw9-hz4ek"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "# Returns the F1 score computed on the predictions\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat=np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat=labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "\n",
        "\n",
        "# Returns the precision, accuracy and recall score computed on the predictions\n",
        "def prec_func(preds, labels):\n",
        "    preds_flat=np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat=labels.flatten()\n",
        "    return precision_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def recall_func(preds, labels):\n",
        "    preds_flat=np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat=labels.flatten()\n",
        "    return recall_score(labels_flat, preds_flat, average='weighted')\n",
        "  \n",
        "\n",
        "def acc_func(preds, labels):\n",
        "    preds_flat=np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat=labels.flatten()\n",
        "    return accuracy_score(labels_flat, preds_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5qf7Etbz7SN"
      },
      "source": [
        "# Evaluates the model using the validation set\n",
        "def evaluate(dataloader_val):\n",
        "  model.eval()\n",
        "  loss_val_total = 0\n",
        "  predictions, true_vals = [], []\n",
        "\n",
        "  for batch in dataloader_val:\n",
        "      batch = tuple(b.to(device) for b in batch)\n",
        "      inputs = {'input_ids': batch[0],\n",
        "        'attention_mask': batch[1],\n",
        "        'labels': batch[2],\n",
        "        }\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = model(**inputs)\n",
        "\n",
        "      loss = outputs[0]\n",
        "      logits = outputs[1]\n",
        "      loss_val_total += loss.item()\n",
        "\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = inputs['labels'].cpu().numpy()\n",
        "      predictions.append(logits)\n",
        "      true_vals.append(label_ids)\n",
        "\n",
        "  loss_val_avg = loss_val_total / len(dataloader_val)\n",
        "\n",
        "  predictions = np.concatenate(predictions, axis=0)\n",
        "  true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "  return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XTBvDqU0HUH"
      },
      "source": [
        "for epoch in tqdm(range(1, epochs + 1)):\n",
        "\n",
        "    model.train()  # model is training\n",
        "\n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {'input_ids': batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels': batch[2]}\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()  # to backpropagate\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
        "                                      1.0)  # prevents the gradient from being too small or too big\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "\n",
        "    \n",
        "    torch.save(model, path)\n",
        "    tqdm.write(f'\\nEpoch {epoch}/{epochs}')\n",
        "\n",
        "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')  # make sure that model is still training\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)  # to check overtraining (or overfitting)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    val_prec = prec_func(predictions, true_vals)\n",
        "    val_recall = recall_func(predictions, true_vals)\n",
        "    val_acc = acc_func(predictions, true_vals)\n",
        "\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score(weighted) : {val_f1}')\n",
        "    tqdm.write(f'Prec Score(weighted) : {val_prec}')\n",
        "    tqdm.write(f'Recall Score(weighted) : {val_recall}')\n",
        "    tqdm.write(f'Acc Score : {val_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33wSWORG753R"
      },
      "source": [
        "#Testing Anti-LGBT content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL3VoeLG0Omi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "99e4fdaa-668f-4bd2-ef65-87423b6ea032"
      },
      "source": [
        "#Load test set\n",
        "data_test = pd.read_excel('homo_dev.xlsx')\n",
        "data_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4b3fdcde-68ee-4e94-b570-c7b659fb690a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Homophobic</td>\n",
              "      <td>Govt must appoint a thiru nangai police to arr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Non-anti-LGBT+ content</td>\n",
              "      <td>Archana Shree what</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Non-anti-LGBT+ content</td>\n",
              "      <td>they probably dont want to live in your devan'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Non-anti-LGBT+ content</td>\n",
              "      <td>Haha she is so cute and innocent              ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Non-anti-LGBT+ content</td>\n",
              "      <td>I love it 💗💗💗</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b3fdcde-68ee-4e94-b570-c7b659fb690a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b3fdcde-68ee-4e94-b570-c7b659fb690a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b3fdcde-68ee-4e94-b570-c7b659fb690a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                    label                       text                        \n",
              "0              Homophobic  Govt must appoint a thiru nangai police to arr...\n",
              "1  Non-anti-LGBT+ content         Archana Shree what                        \n",
              "2  Non-anti-LGBT+ content  they probably dont want to live in your devan'...\n",
              "3  Non-anti-LGBT+ content  Haha she is so cute and innocent              ...\n",
              "4  Non-anti-LGBT+ content              I love it 💗💗💗                        "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test.to_csv('test.csv')"
      ],
      "metadata": {
        "id": "4R3zAcm6lU04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = pd.read_csv('test.csv')\n",
        "data_test = data_test.dropna()\n",
        "data_test = data_test.rename(columns={'text                        ': 'text'})\n",
        "data_test = data_test.drop(['label'], axis=1)"
      ],
      "metadata": {
        "id": "G3Y-tyATzxPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeYslRqT0YQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72eac64a-ac7b-4563-c6ef-9c808dcc6883"
      },
      "source": [
        "# Encode validation dataset using the tokenizer\n",
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    data_test.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,  \n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwYw3fXA0a8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622f41c2-0a7a-42dd-b30f-3b39c539e9c1"
      },
      "source": [
        "# Extract IDs, attention masks and labels from validation dataset\n",
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test)\n",
        "print(\"Test dataset length: {}\".format(len(dataset_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset length: 792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkAxMevN0en8"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "dataloader_test = DataLoader(dataset_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2ohPvh90hhN"
      },
      "source": [
        "# Evaluates the model using the validation set\n",
        "def predict(dataset_test):\n",
        "    predictions = []\n",
        "\n",
        "    for row in dataset_test:\n",
        "      row = tuple(r.to(device) for r in row)\n",
        "      inputs = {'input_ids': row[0],\n",
        "        'attention_mask': row[1]\n",
        "        }\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = model(**inputs)\n",
        "\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      predictions.append(logits)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Predict values for test dataset\n",
        "predictions = predict(dataloader_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBE9CnIK0kYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ce3b6a-df70-433d-fda3-26f95f3cca27"
      },
      "source": [
        "print(len(predictions))\n",
        "results = []\n",
        "for i, prediction in enumerate(predictions):\n",
        "  predicted = np.argmax(prediction, axis=1)[0]\n",
        "  # print(f\"index: {i} -- prediction: {predicted}\")\n",
        "  results.append(predicted)\n",
        "\n",
        "print(results)\n",
        "print(results.count(0))\n",
        "print(results.count(1))\n",
        "print(results.count(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "792\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "772\n",
            "20\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj9yXbei0o5U"
      },
      "source": [
        "pred = []\n",
        "for prediction in results:\n",
        "  pred.append(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHoewn020rN8"
      },
      "source": [
        "#Predict misogyny\n",
        "data_test['pred'] = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyCeLJE_0uwF"
      },
      "source": [
        "#Save the predicted labels in a csv file \n",
        "data_test.to_excel('final_pred_homo.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R8VJCI9wI0TX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}